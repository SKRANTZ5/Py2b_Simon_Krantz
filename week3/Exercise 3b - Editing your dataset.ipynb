{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e6f4f9a",
   "metadata": {},
   "source": [
    "<div style=\"background: black; padding: 10px 250px\"><img src=\"https://www.veldikompetens.se/wp-content/themes/consid/static/icons/VeldiKompetens_Logo_Web_Negative.svg\" title=\"Veldi kompetens\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93bffd",
   "metadata": {},
   "source": [
    "<hr><h1><center>Exercise 3b - Editing and updating your dataset</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa6de2",
   "metadata": {},
   "source": [
    "<h3>Instructions </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add1cd83",
   "metadata": {},
   "source": [
    "<p>In this exercise you will learn more about editing and updating your dataset and we will also perform operations such as cleaning and removing data. We will also get a better overview of the dataset we are working with.  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32acb796",
   "metadata": {},
   "source": [
    "<h3> 1. Setup </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b95b4a",
   "metadata": {},
   "source": [
    "Authors note: I actually encountered a very interesting issue initially working with this dataset. Pandas has a standard of setting empty inputs in the csv file to NaN (Not a Number) and is the traditional approach of working with missing data. If something is missing by default set it to NaN. However! if you remove the na_values below you will see that bean type is still just an empty string. To fix this I started by reseraching into the csv file and found that instead of the usual format col1val,col2val,col3val,,col5val where there is nothing between col3 and col5 there was instead a blank space i.e col3, ,col5. Upon further examining what this blank space represented it appears to be a special type of encoding for blankspaces namely \\xao0 (read some about it if you want to! Very interesting issue.) It can however be solved with the na_values parameter below. This is how it is working with data in real life! Things are never perfect:)\n",
    "\n",
    "(na_values is a parameter that tells pandas what to identify as NaN values)\n",
    "\n",
    "Neccesary libraries and the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bc3b14d9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 8, saw 9\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Remeber you need to have the file accessible locally\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflavors_of_cacao.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_values\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\xa0\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m df\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 8, saw 9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Remeber you need to have the file accessible locally\n",
    "df = pd.read_csv(\"flavors_of_cacao.csv\", na_values = [\" \", u'\\xa0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d44b12",
   "metadata": {},
   "source": [
    "<h3> 2. Examining our data</h3>\n",
    "<h4> 2.1 Cleaning the data </h4>\n",
    "<p>As can be seen in the bean type column there are missing values, logically this seems odd right? It might be considered an important column for possible evaluations on what gives a particular chocolate a good rating. Further discussion on this topic will be presented in exercise 3b, but for now  we are going to work with something called cleaning data and how we can do it in pandas. Essentially cleaning data is removing invalid samples from the dataset and the goal of cleaning data can be summarized as achieving the points below. </p>\n",
    "<ul>\n",
    "    <li>Is there any row that has no value in any column but still exist as an entry? If so delete.</li>\n",
    "    <li>Remove samples which are extreme outliers and does not really make any logical sense</li>\n",
    "    <li>Remove duplicates (Of course depends on data, sometimes duplicates are part of the structure)</li>\n",
    "</ul>\n",
    "<p> Lets check out the bean type column which from the getgo seems pretty scarce in data  and evaluate how many of the samples have NaN values</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c50fbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful things to have access to\n",
    "samples = len(df)\n",
    "columns = len(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "897de0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888\n",
      "Samples missing bean type value: 49.47075208913649%\n"
     ]
    }
   ],
   "source": [
    "# Note: Whilst you definitely can do a forloop use pandas/numpy instead! They are much faster and a better practice\n",
    "bean_col = df[\"Bean\\nType\"]\n",
    "print(bean_col.isna().sum())\n",
    "samples_missing_bean = bean_col.isna().sum()\n",
    "\n",
    "print(f\"Samples missing bean type value: {samples_missing_bean/samples * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a24b8",
   "metadata": {},
   "source": [
    "Actually, lets perform this check for our entire dataset, just to get a better feel for the data. Usually you would do this much smoother and print less, but for educations sake we go with the more pedalogical approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb9a9705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column Company \n",
      "(Maker-if known) is missing 0.0% of data! \n",
      "\n",
      "\n",
      "The column Specific Bean Origin\n",
      "or Bar Name is missing 0.0% of data! \n",
      "\n",
      "\n",
      "The column REF is missing 0.0% of data! \n",
      "\n",
      "\n",
      "The column Review\n",
      "Date is missing 0.0% of data! \n",
      "\n",
      "\n",
      "The column Cocoa\n",
      "Percent is missing 0.0% of data! \n",
      "\n",
      "\n",
      "The column Company\n",
      "Location is missing 0.0% of data! \n",
      "\n",
      "\n",
      "The column Rating is missing 0.0% of data! \n",
      "\n",
      "\n",
      "The column Bean\n",
      "Type is missing 49.47075208913649% of data! \n",
      "\n",
      "\n",
      "The column Broad Bean\n",
      "Origin is missing 4.1225626740947074% of data! \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_nan():\n",
    "\n",
    "    for col in df.columns:\n",
    "        column_name = col\n",
    "        working_col = df[col]\n",
    "    \n",
    "        working_col_missing_bean = working_col.isna().sum()\n",
    "    \n",
    "        print(f\"The column {column_name} is missing {working_col_missing_bean/samples * 100}% of data! \\n\\n\")\n",
    "        \n",
    "count_nan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b5035",
   "metadata": {},
   "source": [
    "Incredible how we could get so much information so quickly right? Lets do some more digging.\n",
    "\n",
    "Lets wait a bit with reasoning about the huge lack of information about bean type, for now lets check if there are rows that are entirely empty and remove those by the looks of it there might be some"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c3830ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "1790    False\n",
      "1791    False\n",
      "1792    False\n",
      "1793    False\n",
      "1794    False\n",
      "Length: 1795, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company \\n(Maker-if known)</th>\n",
       "      <th>Specific Bean Origin\\nor Bar Name</th>\n",
       "      <th>REF</th>\n",
       "      <th>Review\\nDate</th>\n",
       "      <th>Cocoa\\nPercent</th>\n",
       "      <th>Company\\nLocation</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bean\\nType</th>\n",
       "      <th>Broad Bean\\nOrigin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company \n",
       "(Maker-if known), Specific Bean Origin\n",
       "or Bar Name, REF, Review\n",
       "Date, Cocoa\n",
       "Percent, Company\n",
       "Location, Rating, Bean\n",
       "Type, Broad Bean\n",
       "Origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This might seem a bit magical, break it down into several lines if you wish!\n",
    "# Essentially df.isna() checks if there is a NaN value and .all(axis=1) checks if this is true in each column!\n",
    "print(df.isna().all(axis=1))\n",
    "nan_samples = df[df.isna().all(axis=1)]\n",
    "nan_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72920f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets go about removing these instances as they only corrupt the data, notice the indexes are still the same as in the original\n",
    "print(nan_samples.index.values)\n",
    "nan_indexes = nan_samples.index.values\n",
    "nan_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8adc576d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company \\n(Maker-if known)</th>\n",
       "      <th>Specific Bean Origin\\nor Bar Name</th>\n",
       "      <th>REF</th>\n",
       "      <th>Review\\nDate</th>\n",
       "      <th>Cocoa\\nPercent</th>\n",
       "      <th>Company\\nLocation</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Peru</td>\n",
       "      <td>647</td>\n",
       "      <td>2011</td>\n",
       "      <td>70%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Congo</td>\n",
       "      <td>749</td>\n",
       "      <td>2011</td>\n",
       "      <td>65%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>749</td>\n",
       "      <td>2011</td>\n",
       "      <td>65%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>781</td>\n",
       "      <td>2011</td>\n",
       "      <td>62%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Brazil, Mitzi Blue</td>\n",
       "      <td>486</td>\n",
       "      <td>2010</td>\n",
       "      <td>65%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company \\n(Maker-if known) Specific Bean Origin\\nor Bar Name   REF  \\\n",
       "0                      A. Morin                       Agua Grande  1876   \n",
       "1                      A. Morin                             Kpime  1676   \n",
       "2                      A. Morin                            Atsane  1676   \n",
       "3                      A. Morin                             Akata  1680   \n",
       "4                      A. Morin                            Quilla  1704   \n",
       "...                         ...                               ...   ...   \n",
       "1790                     Zotter                              Peru   647   \n",
       "1791                     Zotter                             Congo   749   \n",
       "1792                     Zotter                      Kerala State   749   \n",
       "1793                     Zotter                      Kerala State   781   \n",
       "1794                     Zotter                Brazil, Mitzi Blue   486   \n",
       "\n",
       "      Review\\nDate Cocoa\\nPercent Company\\nLocation  Rating  \n",
       "0             2016            63%            France    3.75  \n",
       "1             2015            70%            France    2.75  \n",
       "2             2015            70%            France    3.00  \n",
       "3             2015            70%            France    3.50  \n",
       "4             2015            70%            France    3.50  \n",
       "...            ...            ...               ...     ...  \n",
       "1790          2011            70%           Austria    3.75  \n",
       "1791          2011            65%           Austria    3.00  \n",
       "1792          2011            65%           Austria    3.50  \n",
       "1793          2011            62%           Austria    3.25  \n",
       "1794          2010            65%           Austria    3.00  \n",
       "\n",
       "[1795 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now lets remove these from the original\n",
    "#df = df.drop(nan_indexes)\n",
    "#count_nan()\n",
    "#len(df)\n",
    "# Note: The above example is a more handson approach, pandas has a builtin-functionality for the same purpose;\n",
    "df.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1812e97",
   "metadata": {},
   "source": [
    "Awesome! Now lets check for duplicates, pandas has a neat functionality builtin which is called duplicated()\n",
    "duplicated returns a pandas series with boolean values of true/false if there is more than one occurence of an identical sample. To create a \"new\" dataframe with only the duplicated values you do as we did above by saying df[]. It creates a new dataframe with only the true values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6279bad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company \\n(Maker-if known)</th>\n",
       "      <th>Specific Bean Origin\\nor Bar Name</th>\n",
       "      <th>REF</th>\n",
       "      <th>Review\\nDate</th>\n",
       "      <th>Cocoa\\nPercent</th>\n",
       "      <th>Company\\nLocation</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bean\\nType</th>\n",
       "      <th>Broad Bean\\nOrigin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company \n",
       "(Maker-if known), Specific Bean Origin\n",
       "or Bar Name, REF, Review\n",
       "Date, Cocoa\n",
       "Percent, Company\n",
       "Location, Rating, Bean\n",
       "Type, Broad Bean\n",
       "Origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just to show\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc72e2ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company \\n(Maker-if known)</th>\n",
       "      <th>Specific Bean Origin\\nor Bar Name</th>\n",
       "      <th>REF</th>\n",
       "      <th>Review\\nDate</th>\n",
       "      <th>Cocoa\\nPercent</th>\n",
       "      <th>Company\\nLocation</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Bean\\nType</th>\n",
       "      <th>Broad Bean\\nOrigin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sao Tome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70%</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Peru</td>\n",
       "      <td>647</td>\n",
       "      <td>2011</td>\n",
       "      <td>70%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Congo</td>\n",
       "      <td>749</td>\n",
       "      <td>2011</td>\n",
       "      <td>65%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Forastero</td>\n",
       "      <td>Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>749</td>\n",
       "      <td>2011</td>\n",
       "      <td>65%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Forastero</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>781</td>\n",
       "      <td>2011</td>\n",
       "      <td>62%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Brazil, Mitzi Blue</td>\n",
       "      <td>486</td>\n",
       "      <td>2010</td>\n",
       "      <td>65%</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company \\n(Maker-if known) Specific Bean Origin\\nor Bar Name   REF  \\\n",
       "0                      A. Morin                       Agua Grande  1876   \n",
       "1                      A. Morin                             Kpime  1676   \n",
       "2                      A. Morin                            Atsane  1676   \n",
       "3                      A. Morin                             Akata  1680   \n",
       "4                      A. Morin                            Quilla  1704   \n",
       "...                         ...                               ...   ...   \n",
       "1790                     Zotter                              Peru   647   \n",
       "1791                     Zotter                             Congo   749   \n",
       "1792                     Zotter                      Kerala State   749   \n",
       "1793                     Zotter                      Kerala State   781   \n",
       "1794                     Zotter                Brazil, Mitzi Blue   486   \n",
       "\n",
       "      Review\\nDate Cocoa\\nPercent Company\\nLocation  Rating Bean\\nType  \\\n",
       "0             2016            63%            France    3.75        NaN   \n",
       "1             2015            70%            France    2.75        NaN   \n",
       "2             2015            70%            France    3.00        NaN   \n",
       "3             2015            70%            France    3.50        NaN   \n",
       "4             2015            70%            France    3.50        NaN   \n",
       "...            ...            ...               ...     ...        ...   \n",
       "1790          2011            70%           Austria    3.75        NaN   \n",
       "1791          2011            65%           Austria    3.00  Forastero   \n",
       "1792          2011            65%           Austria    3.50  Forastero   \n",
       "1793          2011            62%           Austria    3.25        NaN   \n",
       "1794          2010            65%           Austria    3.00        NaN   \n",
       "\n",
       "     Broad Bean\\nOrigin  \n",
       "0              Sao Tome  \n",
       "1                  Togo  \n",
       "2                  Togo  \n",
       "3                  Togo  \n",
       "4                  Peru  \n",
       "...                 ...  \n",
       "1790               Peru  \n",
       "1791              Congo  \n",
       "1792              India  \n",
       "1793              India  \n",
       "1794             Brazil  \n",
       "\n",
       "[1795 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_indexes = df[df.duplicated()].index\n",
    "df = df.drop(duplicate_indexes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "747ac6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly after having removed samples you usually re-index the dataset before proceeding and lets save our edited dataset\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(\"edited_choco.csv\", index=False)\n",
    "#In Pandas there is also a way of counting duplicates which may be very relevant for our case since we have a lot of duplicates in terms of companies lets examine this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55172d",
   "metadata": {},
   "source": [
    "In Pandas there is also a way of counting duplicates which may be very relevant for our case since we have a lot of duplicates in terms of for example companies lets examine this. In the below code the functionality pivot_table can be used to output a table of the desired readings, you can do a lot of awesome stuff with this function but this is the most simple example. aggfunc is used to describe what action you want to perform on the column, with \"size\" being a keyword for counting duplicates. NOTE; NaN values are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0065155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "1.00      4\n",
       "1.50     10\n",
       "1.75      3\n",
       "2.00     32\n",
       "2.25     14\n",
       "2.50    127\n",
       "2.75    259\n",
       "3.00    341\n",
       "3.25    303\n",
       "3.50    392\n",
       "3.75    210\n",
       "4.00     98\n",
       "5.00      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(columns=[\"Rating\"], aggfunc=\"size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45a32b7",
   "metadata": {},
   "source": [
    "<h4>2.3 Time for some Q/A! </h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7da3f0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1795"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1: Drop the below sample from the table it is enough to check that there is one less sample than the code above\n",
    "drop_index = 394\n",
    "#TODO; no need to reassign the updated value to the df.\n",
    "\n",
    "df.drop(drop_index)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9dd64",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "<div class=\"output_subarea output_html rendered_html output_result\" dir=\"auto\"><div>\n",
    "<style scoped=\"\">\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Company(Maker-if known)</th>\n",
    "      <th>Specific Bean Origin or Bar Name</th>\n",
    "      <th>REF</th>\n",
    "      <th>Review Date</th>\n",
    "      <th>Cocoa Percent</th>\n",
    "      <th>Company Location</th>\n",
    "      <th>Rating</th>\n",
    "      <th>Bean Type</th>\n",
    "      <th>Broad Bean Origin</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Agua Grande</td>\n",
    "      <td>1876.0</td>\n",
    "      <td>2016.0</td>\n",
    "      <td>63%</td>\n",
    "      <td>France</td>\n",
    "      <td>3.75</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Sao Tome</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Kpime</td>\n",
    "      <td>1676.0</td>\n",
    "      <td>2015.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>France</td>\n",
    "      <td>2.75</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Togo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Atsane</td>\n",
    "      <td>1676.0</td>\n",
    "      <td>2015.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>France</td>\n",
    "      <td>3.00</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Togo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Akata</td>\n",
    "      <td>1680.0</td>\n",
    "      <td>2015.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>France</td>\n",
    "      <td>3.50</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Togo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>4</th>\n",
    "      <td>A. Morin</td>\n",
    "      <td>Quilla</td>\n",
    "      <td>1704.0</td>\n",
    "      <td>2015.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>France</td>\n",
    "      <td>3.50</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Peru</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>...</th>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "      <td>...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1790</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Peru</td>\n",
    "      <td>647.0</td>\n",
    "      <td>2011.0</td>\n",
    "      <td>70%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.75</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Peru</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1791</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Congo</td>\n",
    "      <td>749.0</td>\n",
    "      <td>2011.0</td>\n",
    "      <td>65%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.00</td>\n",
    "      <td>Forastero</td>\n",
    "      <td>Congo</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1792</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Kerala State</td>\n",
    "      <td>749.0</td>\n",
    "      <td>2011.0</td>\n",
    "      <td>65%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.50</td>\n",
    "      <td>Forastero</td>\n",
    "      <td>India</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1793</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Kerala State</td>\n",
    "      <td>781.0</td>\n",
    "      <td>2011.0</td>\n",
    "      <td>62%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.25</td>\n",
    "      <td>NaN</td>\n",
    "      <td>India</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1794</th>\n",
    "      <td>Zotter</td>\n",
    "      <td>Brazil, Mitzi Blue</td>\n",
    "      <td>486.0</td>\n",
    "      <td>2010.0</td>\n",
    "      <td>65%</td>\n",
    "      <td>Austria</td>\n",
    "      <td>3.00</td>\n",
    "      <td>NaN</td>\n",
    "      <td>Brazil</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<p>1794 rows × 9 columns</p>\n",
    "</div></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fb4c4a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company\\nLocation\n",
       "Amsterdam              4\n",
       "Argentina              9\n",
       "Australia             49\n",
       "Austria               26\n",
       "Belgium               40\n",
       "Bolivia                2\n",
       "Brazil                17\n",
       "Canada               125\n",
       "Chile                  2\n",
       "Colombia              23\n",
       "Costa Rica             9\n",
       "Czech Republic         1\n",
       "Denmark               15\n",
       "Domincan Republic      5\n",
       "Ecuador               54\n",
       "Eucador                1\n",
       "Fiji                   4\n",
       "Finland                2\n",
       "France               156\n",
       "Germany               35\n",
       "Ghana                  1\n",
       "Grenada                3\n",
       "Guatemala             10\n",
       "Honduras               6\n",
       "Hungary               22\n",
       "Iceland                3\n",
       "India                  1\n",
       "Ireland                4\n",
       "Israel                 9\n",
       "Italy                 63\n",
       "Japan                 17\n",
       "Lithuania              6\n",
       "Madagascar            17\n",
       "Martinique             1\n",
       "Mexico                 4\n",
       "Netherlands            4\n",
       "New Zealand           17\n",
       "Niacragua              1\n",
       "Nicaragua              5\n",
       "Peru                  17\n",
       "Philippines            1\n",
       "Poland                 8\n",
       "Portugal               3\n",
       "Puerto Rico            4\n",
       "Russia                 1\n",
       "Sao Tome               4\n",
       "Scotland              10\n",
       "Singapore              3\n",
       "South Africa           3\n",
       "South Korea            5\n",
       "Spain                 25\n",
       "St. Lucia              2\n",
       "Suriname               1\n",
       "Sweden                 5\n",
       "Switzerland           38\n",
       "U.K.                  96\n",
       "U.S.A.               764\n",
       "Venezuela             20\n",
       "Vietnam               11\n",
       "Wales                  1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2 Output the amount of duplicates in the company location\n",
    "df.pivot_table(columns=[\"Company\\nLocation\"], aggfunc=\"size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0271abc9",
   "metadata": {},
   "source": [
    "Expected output: \n",
    "<pre>Company Location\n",
    "Amsterdam              4\n",
    "Argentina              9\n",
    "Australia             49\n",
    "Austria               26\n",
    "Belgium               40\n",
    "Bolivia                2\n",
    "Brazil                17\n",
    "Canada               125\n",
    "Chile                  2\n",
    "Colombia              23\n",
    "Costa Rica             9\n",
    "Czech Republic         1\n",
    "Denmark               15\n",
    "Domincan Republic      5\n",
    "Ecuador               54\n",
    "Eucador                1\n",
    "Fiji                   4\n",
    "Finland                2\n",
    "France               156\n",
    "Germany               35\n",
    "Ghana                  1\n",
    "Grenada                3\n",
    "Guatemala             10\n",
    "Honduras               6\n",
    "Hungary               22\n",
    "Iceland                3\n",
    "India                  1\n",
    "Ireland                4\n",
    "Israel                 9\n",
    "Italy                 63\n",
    "Japan                 17\n",
    "Lithuania              6\n",
    "Madagascar            17\n",
    "Martinique             1\n",
    "Mexico                 4\n",
    "Netherlands            4\n",
    "New Zealand           17\n",
    "Niacragua              1\n",
    "Nicaragua              5\n",
    "Peru                  17\n",
    "Philippines            1\n",
    "Poland                 8\n",
    "Portugal               3\n",
    "Puerto Rico            4\n",
    "Russia                 1\n",
    "Sao Tome               4\n",
    "Scotland              10\n",
    "Singapore              3\n",
    "South Africa           3\n",
    "South Korea            5\n",
    "Spain                 25\n",
    "St. Lucia              2\n",
    "Suriname               1\n",
    "Sweden                 5\n",
    "Switzerland           38\n",
    "U.K.                  96\n",
    "U.S.A.               764\n",
    "Venezuela             20\n",
    "Vietnam               11\n",
    "Wales                  1\n",
    "dtype: int64</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69faf61",
   "metadata": {},
   "source": [
    "Thats it for this exercise! In the next exercise we will tackle some other problems related to transforming our data types, noramlizing values and reason a bit about the almost 50% missing bean types:) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebd5b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
